# ViraLoop – Klaster Ray (KubeRay) do rozproszonych obliczeń GPU
#
# Ray 2.53.0 (część PyTorch Foundation, 35K+ gwiazdek GitHub)
# OpenAI używa Ray do trenowania ChatGPT na 2000+ węzłach.
#
# Konfiguracja:
# - Ray Head: zarządzanie klastrem, GCS, Serve controller
# - Ray Workers: GPU (H100/A100/RTX 4090) do generowania wideo
# - KubeRay Operator: zarządzanie cyklem życia klastra
# - Autoskalowanie na podstawie głębokości kolejki zadań

apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: viraloop-ray-cluster
  namespace: viraloop
  labels:
    app: ray-cluster
spec:
  rayVersion: "2.53.0"
  enableInTreeAutoscaling: true

  # ── Węzeł Head ──────────────────────────────────────────────────────────
  headGroupSpec:
    serviceType: ClusterIP
    replicas: 1
    rayStartParams:
      dashboard-host: "0.0.0.0"
      num-cpus: "0"  # Head nie wykonuje zadań
      block: "true"
    template:
      spec:
        containers:
          - name: ray-head
            image: rayproject/ray:2.53.0-gpu
            resources:
              requests:
                cpu: "4"
                memory: "16Gi"
              limits:
                cpu: "8"
                memory: "32Gi"
            ports:
              - containerPort: 6379  # Redis GCS
              - containerPort: 8265  # Dashboard
              - containerPort: 10001 # Client port
              - containerPort: 8000  # Ray Serve
            env:
              - name: RAY_GRAFANA_HOST
                value: "http://grafana:3001"
              - name: RAY_PROMETHEUS_HOST
                value: "http://prometheus:9090"

  # ── Grupy robocze (GPU) ──────────────────────────────────────────────────
  workerGroupSpecs:

    # Grupa H100 – generowanie wideo premium (Wan2.2 14B MoE)
    - groupName: gpu-h100
      replicas: 2
      minReplicas: 0  # Skaluj do 0 gdy brak zadań
      maxReplicas: 8
      rayStartParams:
        num-cpus: "16"
        num-gpus: "1"
        resources: '{"GPU_TYPE": "H100"}'
      template:
        spec:
          nodeSelector:
            viraloop.pl/gpu-type: h100
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: ray-worker-h100
              image: viraloop/ray-worker-wan2:latest
              resources:
                requests:
                  cpu: "16"
                  memory: "80Gi"
                  nvidia.com/gpu: "1"
                limits:
                  cpu: "16"
                  memory: "80Gi"
                  nvidia.com/gpu: "1"
              volumeMounts:
                - name: model-cache
                  mountPath: /models
          volumes:
            - name: model-cache
              persistentVolumeClaim:
                claimName: model-cache-h100

    # Grupa RTX 4090 – generowanie wideo ekonomiczne (HunyuanVideo 1.5)
    - groupName: gpu-rtx4090
      replicas: 4
      minReplicas: 2  # Zawsze min. 2 węzły gotowe
      maxReplicas: 16
      rayStartParams:
        num-cpus: "8"
        num-gpus: "1"
        resources: '{"GPU_TYPE": "RTX4090"}'
      template:
        spec:
          nodeSelector:
            viraloop.pl/gpu-type: rtx4090
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: ray-worker-rtx4090
              image: viraloop/ray-worker-hunyuan:latest
              resources:
                requests:
                  cpu: "8"
                  memory: "24Gi"
                  nvidia.com/gpu: "1"
                limits:
                  cpu: "8"
                  memory: "24Gi"
                  nvidia.com/gpu: "1"
              env:
                # HunyuanVideo 1.5: 8.3B parametrów, 14GB VRAM (lub 8GB z offloadingiem)
                - name: CUDA_VISIBLE_DEVICES
                  value: "0"
                - name: PYTORCH_CUDA_ALLOC_CONF
                  value: "max_split_size_mb:512"
